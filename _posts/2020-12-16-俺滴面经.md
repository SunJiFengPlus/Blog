---
layout:     post
title:      俺滴面经
subtitle:   
date:       2020-12-16
author:     孙继峰
header-img: img/th.jpg
catalog: true
tags:
    - 面经
---



> 真心希望这种[船货崇拜](https://mp.weixin.qq.com/s/sgDZ00aPzbh_YzXlebEX-w)的行业现行尽快改变. 现实就是这样, 无奈于现状, 想进大厂、高薪资就需要走这条路.



# Java



## JVM



### JVM 内存区划分

**堆**: 线程共享的, 存储所有的实例对象, 也可能存储逃逸分析后的局部变量

**方法区**: 线程共享的, 存储类信息、常量、静态变量

**虚拟机栈**: 线程私有的, 每个线程在创建时都会创建一个虚拟机栈，其内部保存一个个的栈帧，对应着一次次的Java方法调用

**本地方法栈**: 线程私有的, 支持对 native 方法的调用, Hotspot 在实现的时候将虚拟机栈和本地方法栈合并了.

**程序计数器**: 线程私有的, 程序计数器会存储当前线程正在执行的Java方法的JVM指令地址, 如果是在执行 native 方法，则是 null

运行时还有直接内存区



### 了解垃圾回收吗?

**哪些是垃圾**

最主要部分就是对象实例，都是存储在堆上的; 还有就是方法区中的元数据等信息，例如类不再使用，卸载该Java类。

- 引用计数算法，就是为对象添加一个引用计数，用于记录对象被引用的情况，如果计数为0，即表示对象可回收。 Java并没有选择引用计数，是因为其存在一个基本的难题，也就是很难处理循环引用关系。
- 可达性分析算法，就是将对象及其引用关系看作一个图，选定活动的对象作为 GC Roots，然后跟踪引用链条，如果一个对象和GC Roots之 间不可达，那么即可认为是可回收对象。JVM会把虚拟机栈中正在引用的对象、静态属性引用的对象和常量，作为GC Roots。



**怎么回收垃圾**

- 复制算法，将活着的对象复制到 survivor 区域，拷贝过程中将对象顺序放置，就可以避免内存碎片化。 这么做的代价是，既然要进行复制，既要提前预留内存空间，有一定的浪费, 基于这个算法的吞吐率适合对年轻代进行回收, 因为年轻代中对象有70% - 95%会被清理.

- 标记清除算法，首先进行标记工作，标识出所有要回收的对象，然后进行清除。不可避免的出现碎片化问题， 这就导致其不适合特别大的堆;

- 标记整理，类似于标记-清除，但为避免内存碎片化，它会在清理过程中将对象移动，以确保移动后的对象占用连续的内存空间。基于这个算法的特点适合对老年代进行垃圾回收, 因为老年带的清理效率低.





### JVM 调优流程

#### 内存空间调优

1. 根据异常, 查看哪些区域空间不足 / 过盛
2. 监控指标信息收集: SpringBoot Admin / jmap / jvisualvm
3. 调整内存区域大小
4. 验证


#### GC吞吐调优

1. 确定优化指标, 比如: 平均吞吐率大于90%
2. GC 日志:  ```-XX:+PrintGCDetails```
3. Parallel Scavenge
4. 验证



#### GC停顿调优

1. 确定优化指标, 比如: YoungGC 时间低于 100 ms / FullGC 时间低于 500 ms
2. 开启 GC 日志:  ```-XX:+PrintGCDetails```
3. Serial  -> Parallel -> G1
4. 验证



## 基础

### 对象的创建过程

### 类加载过程

### 输入流输出流

### 反射有用到过吗?



## 并发



### 有用过锁吗?

有用到 ```synchronized```、```Lock``` 与基于 Redis 的分布式锁.

```synchronized``` 一开始并不重, 只是经过锁膨胀之后才慢慢变得重. 一开始只是无锁状态, 当一个线程获取锁时, 线程可以直接获取锁, 这时候膨胀为偏向锁, 通过比较 ThreadID 进行加锁. 当有多个线程交替获取锁时, 会膨胀为轻量级锁, 通过自选等待来加锁. 当有多个线程同时获取锁时, 会膨胀为重量级锁, 通过操作系统的 mutex 锁进行互斥, 这时候的消耗才是最高的, 申请和释放锁时都需要从用户态切换到内核态再切回用户态.

```Lock``` 的底层实现基于 ```Unsafe::compareAndSet``` 方法, 对 ```volatile``` 变量进行 CAS 操作来进行加锁. ```Unsafe::compareAndSet``` 使用这个方法将工作内存与主内存的值比较, 成功则赋值.  ```volatile``` 的语义, 它能保证对这个变量的写操作能立即导致其他线程的工作内存失效, 直接从主内存中获取该变量. ```volatile``` 与 ```Unsafe::compareAndSet```结合完成锁的功能.

基于 Redis 的分布式锁是使用开源客户端 [Redisson](https://github.com/redisson/redisson) 实现的. Redisson 本身提供了分布式锁的实现, 底层原理是基于 Lua Script, 加锁发送给 Redis Server 一段 Lua Script, 其中逻辑就是如果没有锁(```exist```), 那就加锁(```hset```)并设置过期时间(```pexpire```). 如果锁已存在(```hexists```), 就叠加一层锁(```hincrby```), 再续锁(```pexpire```). 使用 Lua Script 保证执行原子性. Redisson 的 API 都是基于 JUC 接口实现的, 锁是可重入锁, 加锁几次就需要解锁几次.



# Spring

### 常用注解

- @Configuration: 声明这是一个配置类, 会将这个类中 @Bean 修饰的方法返回值注入到容器中
- @Autowire: 将容器中对象注入进来
- @RequestMapping / @GetMapping / @PostMapping: 标识这是处理请求的方法
- @Transactional: 声明这个方法是事务的, 执行成功提交, 执行抛异常回滚



### AOP

### IOC

### 谈谈你对 Springboot Starter 的理解

### 事务传播行为

### Spring 用到了哪些设计模式



# SpringCloud



## Nacos



### 对 Nacos 的了解

**服务注册**：Nacos Client 向 Nacos Server 注册自己

**服务心跳**：Nacos Client 会维护一个定时心跳来持续通知 Nacos Server, 说明服务一直处于可用状态

**服务同步**：Nacos Server 集群之间会互相同步服务实例，用来保证服务信息的一致性

**服务发现**：Nacos Client 在调用服务提供者的服务时，会请求 Nacos Server, 获取上面注册的服务清单, 并且缓存在 Nacos  Client 本地, 同时会在 Nacos Client 开启一个定时任务定时拉取服务端最新的注册表信息更新到本地缓存

**服务健康检查**：Nacos  Server 会开启一个定时任务用来检查注册服务实例的健康情况, 对于超过 15s 没有收到客户端心跳的实例会将它的healthy属性置为false(客户端服务发现时不会发现)，如果某个实例超过30秒没有收到心跳，直接剔除该实例

**配置中心**: Nacos Client 会维护一个定时任务去拉取 Nacos Server 的最新配置, 并缓存一份在本地



## Sentinel

### 限流算法



## Gateway



# 中间件



## MySQL



### SQL 优化有做过吗?

服务从上线至今没有对 Web 模块的 SQL 进行优化过, 也是得益于我们选用的 PolarDB, 有业务需求那就建表建索引, 再有业务需求就加索引, 即使是大表也是毫秒级延时. 但在 OffLine 模块中就不一样了, SQL 的写法就比较随便了, 全部查询, 多表 JOIN 都有, 也因为这个出过一次事故, 实例的响应时间整体飙升, 找运维人员定位到是实例连接数不够了, 然后导出了一份慢 SQL Template, 发现有都是 OffLine 模块长期占用连接导致的. 我们的做法就是把大 SQL 拆成小 SQL, 全表查询拆成了多个小查询, 创建一个累加器, 把每次小 SQL 的数据收集并聚合.

> 面试官肯定不希望你这么回答, 答完上面这些再开始背书

实际优化经验比较少, 接着就根据我的了解, case by case 的说吧

- EXPLAIN 一下 SQL, 观察 type, 非离线任务的 SQL 至少要达到 RANGE 级别
- 不要全模糊查询, 不要左模糊查询
- WHERE 中不要有函数 select * from users where YEAR(adddate) < 2007
- 使用 IN, 不要 NOT IN
- UNION 代替 OR
- 要默认值, 不要 null
- 要等值查询, 不要范围查询
- 不要隐式转换 WHERE gender = 1 / WHERE gender = '1'



### 事务隔离级别

**READ-UNCOMMITTED(读取未提交)：** 最低的隔离级别，允许读取尚未提交的数据变更，**可能会导致脏读、幻读或不可重复读**

**READ-COMMITTED(读取已提交):** 允许读取并发事务已经提交的数据，**可以阻止脏读，但是幻读或不可重复读仍有可能发生**

**REPEATABLE-READ（可重读）:**  对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，**可以阻止脏读和不可重复读，但幻读仍有可能发生。**

**SERIALIZABLE(可串行化):** 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，**该级别可以防止脏读、不可重复读以及幻读**。



### 事务特性

**原子性：** 事务的原子性确保动作要么全部完成，要么完全不起作用；

**一致性：** 执行事务前后，数据保持一致；

**隔离性**  并发访问数据库时，一个用户的事物不被其他事物所干扰，各并发事务之间数据库是独立的；

**持久性:**  一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。



### INNODB



### 为什么索引快





## Redis

### Redis数据结构

- String: 字符串, 对应操作 get 、 set 、 del 、 incr、 decr
- Hash: KV结构, 对应操作 hget、hmget、hdel、hincrby
- List: 双向链表, 对应操作 lpush、lpop、rpush、rpop
- Set: 不重复集合, 对应操作 sset srem sismember smembers
- Zset: 按权重排序的集合, 对应操作 zadd zrange



### 过期算法



### 持久化机制



## MQ





# 项目



### 如何推动 TDD 落地



### 商品服务从0到1的过程

背景: 商品逻辑耦合于上游各个服务x, 痛点就是难于管理, 决定拆分沉淀为商品服务.

确定通用语言: 为避免和产品、测试、开发人员沟通歧义, 我们首先确定了通用语言, 按照商品的生命周期划分出了几个概念, 我们把商家上传的商品叫商品审核单, 审核通过后买家可见的商品叫浏览商品, 买家下单的商品叫订单项, 退款流程中的商品叫商品售后单.

确定服务边界: 这个流程主要的目的就是确定哪些逻辑商品服务需要处理, 哪些逻辑商品服务不需要处理. 比如查询商品的活动价格, 按照行为名称看是和商品有关系, 但是仔细分析活动是属于运营子域的, 活动价也是运营子域的内容.

任务分解: 将每一个接口拆分成若干个 case, 去找测试、产品、原来的维护者确认, 避免开发完成后的扯皮与返工. 每一个 case 最后以测试用例的形式验证, 通过测试用例了, 就证明代码是可工作的, 功能是被测试、产品、原维护者认可的.

编写测试用例，写代码，通过测试用例，通过check style静态检查，找人review，测试，预发布，上线.



### 解决过哪些技术难题?

背景: Gateway里打印了接口名与相应时间, 日志收集中配置了报警, 依赖报警感知接口超时率.

#### 1.接口超时

排查: 从请求体上看一次请求了1000多个资源, 与上游业务确认后确定是正常的用户请求. 从代码中看不出任何猫腻, 借助 Arthas attach 到线上应用后对接口方法链路进行耗时分析.发现两处验证耗时的地方, 将 redis client 返回的数据(本身是Map结构,K:属性名, V:属性值)序列化为 json 又序列化为领域对象, 另一个是对象拷贝(```BeanUtils::copyProperty```).

解决: 使用 Hutool 的 ```BeanUtil::toBean``` 直接把 Map 转换为 Bean, 将属性拷贝全部替换为 Setter

验证: 运行全部测试用例, 确保未破坏已有功能, 运行JMH, 确保重构后的接口将再当前场景下不会再超时.



#### 2.Redis 查询慢

排查: Arthas attach 线程观察到 redis client 执行缓慢, 找运维人员确认 RDS-Redis 实例, 连接数有波峰.

分析: 项目中有一些极其不恰当的 Redis 实践, 把整个表的数据都使用一个 Hash Key 存储了, 根据28原则, 那肯定也有大量长时间不被访问的 field. 更改存储结构需要改动很多点, 代价比较大.

解决: 使用 Redisson 的 ```RMapCache``` 对每一个 Field 设置过期时间, Redisson 用定时任务去删除过期的 Field.



#### 3. 数据库死锁

排查: 错误都在log里写明白的  ```Deadlock found when trying to get lock; try restarting transaction```

分析: 异常在 MyBatis-Plus 的  ```ServiceImpl::updateBatchById``` 方法中抛出,  在执行```SqlSession::flushStatements``` 时会去对库里的记录加锁, 在并发情况下批量更新用户1、用户2, 与更新用户2、用户1, 获取锁的顺序不一致, 一个事务持有了用户1的锁, 请求用户2, 另外一个事务持久用户2的锁, 请求用户1的锁, 从而导致死锁.

解决: 破坏一个死锁的必要条件: **循环等待**. 把这个条件破坏掉就可以了, 对于要进行批量更新的数据, 对其安装id排序, 在进行批量更新就没有问题了.



### TCC 介绍



### 服务怎么拆分



# Linux

### Linux 命令

- ls : 显示当前目录下的目录和文件

- mkdir: 创建目录

- cd: 切换目录

- touch: 创建文件

- vim: 编辑文本

- tail: 查看文件尾部

- grep: 过滤文本

  

# 手撕编程题

#### 冒泡排序

#### 笛卡尔积

#### 集合的交集

#### 集合去重

#### 判断一个IP是否合法

#### 去重输出字符串(abccdce -> abcde)

#### 超长整数求和

#### 验证一个字符串是否是数字

# 网络

### HTTP请求全流程





# 你有什么问题想问我?

公司内有没有 DevOps / 敏捷文化? 都有什么相关活动?

是否有云原生文化?
